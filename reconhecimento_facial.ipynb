{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyMozSry2rn4B8Nw3VoVgs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guilherme-ro/reconhecimento-facial-com-mtcnn-e-facenet/blob/main/reconhecimento_facial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mUUEOMatn3r",
        "outputId": "8a47ba3a-bc86-486f-e68d-a3d42087fb97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Instalando bibliotecas. Por favor, aguarde...\n",
            "Found existing installation: face-recognition 1.3.0\n",
            "Uninstalling face-recognition-1.3.0:\n",
            "  Successfully uninstalled face-recognition-1.3.0\n",
            "Found existing installation: dlib 19.24.6\n",
            "Uninstalling dlib-19.24.6:\n",
            "  Successfully uninstalled dlib-19.24.6\n",
            "Requirement already satisfied: mtcnn in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: lz4 in /usr/local/lib/python3.12/dist-packages (4.4.4)\n",
            "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from mtcnn) (1.5.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Collecting keras-facenet\n",
            "  Downloading keras-facenet-0.3.2.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: mtcnn in /usr/local/lib/python3.12/dist-packages (from keras-facenet) (1.0.0)\n",
            "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from mtcnn->keras-facenet) (1.5.2)\n",
            "Requirement already satisfied: lz4>=4.3.3 in /usr/local/lib/python3.12/dist-packages (from mtcnn->keras-facenet) (4.4.4)\n",
            "Building wheels for collected packages: keras-facenet\n",
            "  Building wheel for keras-facenet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-facenet: filename=keras_facenet-0.3.2-py3-none-any.whl size=10367 sha256=e75c8a5caa2b63728f5c7c3a960a1d75fff80c1c3198e5a19510c2c0f1ef517d\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/b0/f5/19ac49fedc10b1df3ee56b096edbcfa39d45794fccc6bcdbbf\n",
            "Successfully built keras-facenet\n",
            "Installing collected packages: keras-facenet\n",
            "Successfully installed keras-facenet-0.3.2\n",
            "[INFO] Baixando imagem de teste placeholder...\n",
            "--2025-10-04 01:49:24--  https://www.publicdomainpictures.net/pictures/320000/velka/group-of-friends-at-a-bar-1574345265o7T.jpg\n",
            "Resolving www.publicdomainpictures.net (www.publicdomainpictures.net)... 172.66.134.60, 172.66.140.55, 2606:4700:10::ac42:863c, ...\n",
            "Connecting to www.publicdomainpictures.net (www.publicdomainpictures.net)|172.66.134.60|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.publicdomainpictures.net/error.php [following]\n",
            "--2025-10-04 01:49:24--  https://www.publicdomainpictures.net/error.php\n",
            "Reusing existing connection to www.publicdomainpictures.net:443.\n",
            "HTTP request sent, awaiting response... 403 Forbidden\n",
            "2025-10-04 01:49:24 ERROR 403: Forbidden.\n",
            "\n",
            "\n",
            "[INFO] Configuração sem Dlib/CUDA concluída. Execute a Célula 2 a seguir.\n"
          ]
        }
      ],
      "source": [
        "# ----------------------------------------------------------------------\n",
        "# CÉLULA 1: INSTALAÇÃO E CONFIGURAÇÃO (MTCNN + FaceNet/Keras-Facenet)\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# 1. Instalação de bibliotecas essenciais\n",
        "print(\"[INFO] Instalando bibliotecas. Por favor, aguarde...\")\n",
        "# Remove qualquer resquício de face_recognition e dlib\n",
        "!pip uninstall -y face_recognition dlib\n",
        "\n",
        "# Instala MTCNN e dependências\n",
        "!pip install mtcnn opencv-python numpy scikit-learn lz4\n",
        "\n",
        "# Instala a implementação do FaceNet para extração de features\n",
        "!pip install keras-facenet\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "from google.colab import files\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Importar as classes necessárias\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "from keras_facenet import FaceNet # Novo modelo de extração de features!\n",
        "\n",
        "# 2. Definição dos caminhos locais e estrutura\n",
        "DATASET_PATH = \"dataset_externo\"\n",
        "ENCODINGS_FILE = \"face_encodings.pickle\"\n",
        "MODEL_FILE = \"face_recognizer_model.pkl\"\n",
        "TEST_IMAGE_PATH = \"data/friends_from_college.webp\"\n",
        "\n",
        "!mkdir -p data\n",
        "!mkdir -p $DATASET_PATH\n",
        "\n",
        "# 3. Download da imagem de teste (Placeholder)\n",
        "print(\"[INFO] Baixando imagem de teste placeholder...\")\n",
        "!wget -O $TEST_IMAGE_PATH \"https://www.publicdomainpictures.net/pictures/320000/velka/group-of-friends-at-a-bar-1574345265o7T.jpg\"\n",
        "\n",
        "print(\"\\n[INFO] Configuração sem Dlib/CUDA concluída. Execute a Célula 2 a seguir.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------------------------\n",
        "# CÉLULA 2: TREINAMENTO DO MODELO (MTCNN para Detecção, FaceNet para Encoding)\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# Inicializa o detector MTCNN e o extrator FaceNet\n",
        "detector_mtcnn = MTCNN()\n",
        "# Esta classe também carrega o modelo neural pré-treinado (FaceNet)\n",
        "encoder_facenet = FaceNet()\n",
        "\n",
        "def treinar_modelo_facenet(dataset_path, encodings_file, model_file, detector, encoder):\n",
        "    print(\"[INFO] Quantificando faces...\")\n",
        "\n",
        "    person_names = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n",
        "\n",
        "    if not person_names:\n",
        "        print(\"[ERRO FATAL] Nenhuma pasta de pessoa encontrada. Verifique se 'dataset_externo' está populada.\")\n",
        "        return None, None\n",
        "\n",
        "    knownEncodings = []\n",
        "    knownNames = []\n",
        "\n",
        "    for name in person_names:\n",
        "        person_dir = os.path.join(dataset_path, name)\n",
        "        print(f\"[INFO] Processando {name}...\")\n",
        "\n",
        "        for filename in os.listdir(person_dir):\n",
        "            if filename.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
        "                path = os.path.join(person_dir, filename)\n",
        "\n",
        "                # 1. Carregar Imagem\n",
        "                image = cv2.imread(path)\n",
        "                if image is None: continue\n",
        "\n",
        "                rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "                # 2. DETECÇÃO FACIAL (MTCNN)\n",
        "                results = detector.detect_faces(rgb)\n",
        "\n",
        "                face_images = []\n",
        "                for face_data in results:\n",
        "                    x, y, w, h = face_data['box']\n",
        "                    # Recorta a face da imagem e redimensiona (FaceNet espera 160x160)\n",
        "                    face = rgb[y:y+h, x:x+w]\n",
        "                    face = cv2.resize(face, (160, 160))\n",
        "                    face_images.append(face)\n",
        "\n",
        "                if face_images:\n",
        "                    # 3. EXTRAÇÃO DE FEATURES/EMBEDDINGS (FaceNet)\n",
        "                    # O FaceNet processa as faces recortadas e retorna os embeddings\n",
        "                    embeddings = encoder.embeddings(face_images)\n",
        "\n",
        "                    for embedding in embeddings:\n",
        "                        knownEncodings.append(embedding)\n",
        "                        knownNames.append(name)\n",
        "\n",
        "    print(f\"[INFO] Total de {len(knownEncodings)} faces processadas para treinamento.\")\n",
        "\n",
        "    if not knownEncodings:\n",
        "        print(\"[ERRO FATAL] Nenhuma face detectada.\")\n",
        "        return None, None\n",
        "\n",
        "    # 4. Serializar Encodings, Treinar SVM e Salvar\n",
        "    print(\"[INFO] Treinando o modelo SVM...\")\n",
        "    le = LabelEncoder()\n",
        "    labels = le.fit_transform(knownNames)\n",
        "\n",
        "    recognizer = SVC(kernel=\"linear\", probability=True)\n",
        "    recognizer.fit(knownEncodings, labels)\n",
        "\n",
        "    print(\"[INFO] Salvando o modelo e o encoder...\")\n",
        "    with open(model_file, 'wb') as f:\n",
        "        pickle.dump((recognizer, le), f)\n",
        "\n",
        "    print(\"[INFO] Treinamento concluído. Modelo salvo em:\", model_file)\n",
        "    return recognizer, le\n",
        "\n",
        "# **EXECUTE O TREINAMENTO**\n",
        "try:\n",
        "    recognizer, le = treinar_modelo_facenet(DATASET_PATH, ENCODINGS_FILE, MODEL_FILE, detector_mtcnn, encoder_facenet)\n",
        "except Exception as e:\n",
        "    print(f\"\\n[ERRO INESPERADO] Ocorreu um erro durante o treinamento: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhn7IY0D3xyo",
        "outputId": "0af61e71-25df-41cb-abd8-b32a64cf4cec"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Quantificando faces...\n",
            "[INFO] Processando annie...\n",
            "[INFO] Processando billy...\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "[INFO] Processando .ipynb_checkpoints...\n",
            "[INFO] Processando cobie...\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
            "[INFO] Total de 2 faces processadas para treinamento.\n",
            "[INFO] Treinando o modelo SVM...\n",
            "[INFO] Salvando o modelo e o encoder...\n",
            "[INFO] Treinamento concluído. Modelo salvo em: face_recognizer_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------------------------\n",
        "# CÉLULA 3: DETECÇÃO, RECONHECIMENTO E VISUALIZAÇÃO (MTCNN + FaceNet)\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# Carregar o modelo treinado e re-inicializar o encoder FaceNet (se a sessão tiver sido reiniciada)\n",
        "try:\n",
        "    with open(MODEL_FILE, 'rb') as f:\n",
        "        (recognizer, le) = pickle.load(f)\n",
        "    print(\"[INFO] Modelo e Label Encoder carregados com sucesso.\")\n",
        "\n",
        "    # Re-inicializa os detectores necessários\n",
        "    detector_mtcnn = MTCNN()\n",
        "    encoder_facenet = FaceNet()\n",
        "except FileNotFoundError:\n",
        "    print(\"[ERRO] Arquivos de modelo não encontrados. Execute a Célula 2 com sucesso.\")\n",
        "    raise SystemExit\n",
        "\n",
        "def reconhecer_multiplas_faces_facenet(image_path, recognizer, le, detector, encoder):\n",
        "    print(f\"[INFO] Processando imagem: {image_path}...\")\n",
        "\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None: return None\n",
        "\n",
        "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # 1. DETECÇÃO FACIAL (MTCNN)\n",
        "    print(\"[INFO] Detectando faces...\")\n",
        "    results = detector.detect_faces(rgb)\n",
        "\n",
        "    face_images = []\n",
        "    boxes_coordinates = []\n",
        "\n",
        "    for face_data in results:\n",
        "        x, y, w, h = face_data['box']\n",
        "\n",
        "        # Recorte e Redimensionamento (160x160)\n",
        "        face = rgb[y:y+h, x:x+w]\n",
        "        face = cv2.resize(face, (160, 160))\n",
        "        face_images.append(face)\n",
        "\n",
        "        # Armazena as coordenadas para desenhar\n",
        "        boxes_coordinates.append((y, x + w, y + h, x)) # (top, right, bottom, left)\n",
        "\n",
        "    names = []\n",
        "    if face_images:\n",
        "        # 2. EXTRAÇÃO DE FEATURES/EMBEDDINGS (FaceNet)\n",
        "        embeddings = encoder.embeddings(face_images)\n",
        "\n",
        "        # 3. CLASSIFICAÇÃO/RECONHECIMENTO (SVM)\n",
        "        for embedding in embeddings:\n",
        "            preds = recognizer.predict_proba([embedding])[0]\n",
        "            j = np.argmax(preds)\n",
        "            proba = preds[j]\n",
        "            name = le.classes_[j]\n",
        "\n",
        "            if proba * 100 > 60:\n",
        "                name = f\"{name}: {proba*100:.1f}%\"\n",
        "            else:\n",
        "                name = \"Desconhecido\"\n",
        "\n",
        "            names.append(name)\n",
        "\n",
        "    # 4. Desenhar Bounding Boxes e Rótulos\n",
        "    for ((top, right, bottom, left), name) in zip(boxes_coordinates, names):\n",
        "        cv2.rectangle(image, (left, top), (right, bottom), (0, 255, 0), 2)\n",
        "        y_text = top - 15 if top - 15 > 15 else top + 15\n",
        "        cv2.putText(image, name, (left, y_text), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    0.75, (0, 255, 0), 2)\n",
        "\n",
        "    print(f\"[INFO] {len(boxes_coordinates)} faces detectadas e rotuladas.\")\n",
        "    return image\n",
        "\n",
        "# **EXECUÇÃO E VISUALIZAÇÃO**\n",
        "output_image = reconhecer_multiplas_faces_facenet(TEST_IMAGE_PATH, recognizer, le, detector_mtcnn, encoder_facenet)\n",
        "\n",
        "if output_image is not None:\n",
        "    print(\"\\n[RESULTADO] Imagem com faces detectadas e reconhecidas:\")\n",
        "\n",
        "    rgb_image = cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    plt.imshow(rgb_image)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    output_path = \"resultado_reconhecimento.jpg\"\n",
        "    cv2.imwrite(output_path, output_image)\n",
        "    print(f\"\\n[INFO] Imagem de resultado salva como: {output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S09HlkGUEuZL",
        "outputId": "3cb6c88a-a131-4238-f642-97f034848f18"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Modelo e Label Encoder carregados com sucesso.\n",
            "[INFO] Processando imagem: data/friends_from_college.webp...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qw4xqwYb6QjA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}